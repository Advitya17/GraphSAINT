network:
  - '100-1-n-relu-mean'             # <dim>-<order>-<norm/bias>-<act>-<aggr>
  - '512-0-n-relu-concat'             # <aggr>: mean / concat
  - '1024-1-n-relu-concat'        
  #- '256-0-nb-n-relu'
  - '512-0-n-relu-concat'
  - '512-1-n-relu-concat'
  - '512-0-n-relu-concat'
  - 'sigmoid'       # output layer: sigmoid for multi-class; softmax for single class
params:
  - lr: 0.01
    weight_decay: 0.0
    norm_weight: 0
    norm_adj: 'rw'
    model: 'gsaint'     # 'gs_mean'  'gsaint'
    q_threshold: 50
    q_offset: 0
    batch_norm: 'tf.nn'
    skip: '1-4'
phase:
#  - end: 15         # end epoch for this phase
#    dropout: 0.0
#    sampler: 'frontier'
#    size_subgraph: 256
#    size_frontier: 120     # 4000
#    order: 1
#    max_deg: 10000
  - end: 50         # end epoch for this phase
    dropout: 0.0
    sampler: 'frontier'
    size_subgraph: 512
    size_frontier: 180     # 4000
    order: 1
    max_deg: 10000
  - end: 80
    dropout: 0.0
    sampler: 'frontier'
    size_subgraph: 1500
    size_frontier: 500
    order: 1
    max_deg: 10000
  - end: 180
    dropout: 0.0
    sampler: 'frontier'
    size_subgraph: 5000
    size_frontier: 1800
    order: 1
    max_deg: 10000
  - end: 350
    dropout: 0.0
    sampler: 'frontier'
    size_subgraph: 8000
    size_frontier: 2500
    order: 1
    max_deg: 10000
