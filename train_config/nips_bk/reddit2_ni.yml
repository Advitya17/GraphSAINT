network:
  ### NOTE ###: an order-1 layer followed by an order-0 layer is equivalent to a single layer in S-GCN (Chen, ICML'18). 
  - '128-1-n-lin-concat'
  - '128-0-n-relu-mean'
  - '128-1-n-relu-concat'
  - '128-0-n-relu-mean'
  - 'softmax'            
params:
  - lr: 0.01
    weight_decay: 0.0   
    norm_loss: 1
    norm_aggr: 0
    norm_beta: 0
    split_beta: 1
    norm_layer: 'all'
    norm_adj: 'rw'
    model: 'gsaint'    
    q_threshold: 100
    q_offset: 0
    batch_norm: 'tf.nn'
    skip: 'noskip'
phase:
  - end: 40
    dropout: 0.0
    sampler: 'khop'
    size_subgraph: 8000
    order: 1
